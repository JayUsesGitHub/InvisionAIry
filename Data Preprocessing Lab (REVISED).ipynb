{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab: Data Preprocessing in Python**\n",
    "\n",
    "**Objective:**\n",
    "Learn how to clean, preprocess, and prepare data for machine learning models using Python. We'll cover handling missing data, encoding categorical variables, feature scaling, and splitting data for training and testing.\n",
    "\n",
    "**Dataset:**\n",
    "We will use a sample dataset that includes both numerical and categorical data. You can try replacing the values from the data to experiment around with the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Import Required Libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data handling, splitting, and preprocessing\n",
    "import numpy as np  # For numerical operations, e.g., handling missing data\n",
    "import pandas as pd  # For working with data in table format (DataFrames)\n",
    "from sklearn.model_selection import train_test_split  # To split data into training and testing sets\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder  # For encoding and scaling data\n",
    "from sklearn.impute import SimpleImputer  # To fill in missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Load the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "     Age    Salary  Country Purchased\n",
      "0  25.0   50000.0      USA       Yes\n",
      "1   NaN   60000.0   France        No\n",
      "2  28.0       NaN  Germany        No\n",
      "3  35.0   80000.0      NaN       Yes\n",
      "4  42.0  120000.0      USA       Yes\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataset with missing values and both numerical and categorical data\n",
    "data = {\n",
    "    'Age': [25, np.nan, 28, 35, 42],  # The 'Age' column has a missing value (NaN)\n",
    "    'Salary': [50000, 60000, np.nan, 80000, 120000],  # The 'Salary' column also has a missing value\n",
    "    'Country': ['USA', 'France', 'Germany', np.nan, 'USA'],  # The 'Country' column has a missing value\n",
    "    'Purchased': ['Yes', 'No', 'No', 'Yes', 'Yes']  # 'Purchased' is a categorical column (binary values: Yes/No)\n",
    "}\n",
    "\n",
    "# Load the data into a Pandas DataFrame (a table-like structure)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Show the original dataset\n",
    "print(\"Original Dataset:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Handling Missing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after handling missing data:\n",
      "     Age    Salary  Country Purchased\n",
      "0  25.0   50000.0      USA       Yes\n",
      "1  32.5   60000.0   France        No\n",
      "2  28.0   77500.0  Germany        No\n",
      "3  35.0   80000.0      USA       Yes\n",
      "4  42.0  120000.0      USA       Yes\n"
     ]
    }
   ],
   "source": [
    "# Step 3.1: Handle missing numerical data (Age and Salary columns)\n",
    "\n",
    "# Specify which columns are numerical\n",
    "numerical_features = ['Age', 'Salary']\n",
    "\n",
    "# Create an imputer to fill missing values in numerical columns with the mean value of that column\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Apply the imputer to the numerical columns\n",
    "df[numerical_features] = imputer_num.fit_transform(df[numerical_features])\n",
    "\n",
    "# Step 3.2: Handle missing categorical data (Country column)\n",
    "\n",
    "# Specify which column is categorical\n",
    "categorical_features = ['Country']\n",
    "\n",
    "# Create an imputer to fill missing values in the categorical column with the most frequent value\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Apply the imputer to the categorical column\n",
    "df[categorical_features] = imputer_cat.fit_transform(df[categorical_features])\n",
    "\n",
    "# Show the dataset after missing values are handled\n",
    "print(\"Dataset after handling missing data:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Encoding Categorical Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after encoding categorical data:\n",
      "     Age    Salary  Purchased  Country_Germany  Country_USA\n",
      "0  25.0   50000.0          1            False         True\n",
      "1  32.5   60000.0          0            False        False\n",
      "2  28.0   77500.0          0             True        False\n",
      "3  35.0   80000.0          1            False         True\n",
      "4  42.0  120000.0          1            False         True\n"
     ]
    }
   ],
   "source": [
    "# Step 4.1: Convert the 'Purchased' column (Yes/No) into numerical values using Label Encoding\n",
    "\n",
    "# Create a label encoder to convert 'Yes' to 1 and 'No' to 0\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply the encoder to the 'Purchased' column\n",
    "df['Purchased'] = label_encoder.fit_transform(df['Purchased'])\n",
    "\n",
    "# Step 4.2: Convert the 'Country' column into multiple columns (one for each country) using One-Hot Encoding\n",
    "# This helps the machine learning model understand the different categories without ranking them\n",
    "\n",
    "# Use get_dummies to create new columns for each unique value in 'Country' (e.g., USA, France)\n",
    "# Set drop_first=True to avoid creating redundant columns\n",
    "df = pd.get_dummies(df, columns=['Country'], drop_first=True)\n",
    "\n",
    "# Show the dataset after encoding categorical data\n",
    "print(\"Dataset after encoding categorical data:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after feature scaling:\n",
      "         Age    Salary  Purchased  Country_Germany  Country_USA\n",
      "0 -1.275038 -1.146829          1            False         True\n",
      "1  0.000000 -0.729800          0            False        False\n",
      "2 -0.765023  0.000000          0             True        False\n",
      "3  0.425013  0.104257          1            False         True\n",
      "4  1.615048  1.772373          1            False         True\n"
     ]
    }
   ],
   "source": [
    "# Machine learning models work better when numerical features are on the same scale\n",
    "# For example, Age ranges from 25 to 42, but Salary ranges from 50,000 to 120,000, so we need to scale them\n",
    "\n",
    "# Create a StandardScaler to scale the numerical features (Age and Salary) to have a mean of 0 and standard deviation of 1\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler to the numerical columns\n",
    "df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])\n",
    "\n",
    "# Show the dataset after feature scaling\n",
    "print(\"Dataset after feature scaling:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Splitting the Dataset into Training and Test Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Features (X_train):\n",
      "         Age    Salary  Country_Germany  Country_USA\n",
      "4  1.615048  1.772373            False         True\n",
      "2 -0.765023  0.000000             True        False\n",
      "0 -1.275038 -1.146829            False         True\n",
      "3  0.425013  0.104257            False         True\n",
      "Test Set Features (X_test):\n",
      "    Age  Salary  Country_Germany  Country_USA\n",
      "1  0.0 -0.7298            False        False\n"
     ]
    }
   ],
   "source": [
    "# To evaluate the performance of a machine learning model, we need to split the data into:\n",
    "# - A training set (to train the model)\n",
    "# - A test set (to test how well the model performs on unseen data)\n",
    "\n",
    "# Step 6.1: Separate the features (X) from the target label (y)\n",
    "\n",
    "# The features (X) are all columns except 'Purchased'\n",
    "X = df.drop('Purchased', axis=1)\n",
    "\n",
    "# The target (y) is the 'Purchased' column, which tells us whether someone purchased or not\n",
    "y = df['Purchased']\n",
    "\n",
    "# Step 6.2: Split the data into training and testing sets\n",
    "# We will use 80% of the data for training and 20% for testing\n",
    "\n",
    "# Use train_test_split to randomly split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Show the resulting training and test sets\n",
    "print(\"Training Set Features (X_train):\\n\", X_train)\n",
    "print(\"Test Set Features (X_test):\\n\", X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "* **Handling Missing Data:** We filled missing values in numerical columns with the mean and in categorical columns with the most frequent value.\n",
    "* **Encoding Categorical Data:** We converted categories into numbers so that machine learning models can understand them.\n",
    "* **Feature Scaling:** We standardized numerical features to ensure they are on the same scale.\n",
    "* **Train-Test Split:** We divided the data into training and test sets to evaluate our model’s performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
