{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style='darkgrid')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm\n",
    "import splitfolders\n",
    "import copy\n",
    "import pathlib\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('brian-tumor-dataset/metadata.csv')\n",
    "print(labels_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set')\n",
    "splitfolders.ratio(data_dir, output='brain', seed=20, ratio=(0.8,0.2))\n",
    "\n",
    "data_dir = pathlib.Path('brain')\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformations pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "train_set = ImageFolder(data_dir / 'train', transform=transform)\n",
    "val_set = ImageFolder(data_dir / 'val', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize train images\n",
    "def visualize_images(dataset, label_map, rows=4, cols=4):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    for i in range(1, rows * cols + 1):\n",
    "        idx = torch.randint(len(dataset), size=(1,)).item()\n",
    "        img, label = dataset[idx]\n",
    "        img_np = img.numpy().transpose(1, 2, 0)\n",
    "        img_np = np.clip(img_np, 0, 1)\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i)\n",
    "        ax.set_title(label_map[label])\n",
    "        ax.axis('off')\n",
    "        ax.imshow(img_np)\n",
    "    \n",
    "    plt.suptitle('Sample Brain Tumor Images')\n",
    "    plt.show()\n",
    "\n",
    "CLA_label = {0: 'Brain Tumor', 1:'Healthy'}\n",
    "visualize_images(train_set, CLA_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_TUMOR(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(CNN_TUMOR, self).__init__()\n",
    "        Cin, Hin, Win = params['input_shape']\n",
    "        init_f = params['init_filters']\n",
    "        num_fc1 = params['fc_units']\n",
    "        num_classes = params['num_classes']\n",
    "        self.dropout_rate = params['dropout_rate']\n",
    "        \n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(init_f, init_f * 2, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(init_f * 2, init_f * 4, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(init_f * 4, init_f * 8, kernel_size=3)\n",
    "        \n",
    "        # flatten size calculation\n",
    "        h, w = self._conv_output_shape(Hin, Win)\n",
    "        self.num_flatten = h * w * init_f * 8\n",
    "        \n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
    "        self.fc2 = nn.Linear(num_fc1, num_classes)\n",
    "\n",
    "    def _conv_output_shape(self, h, w):\n",
    "        def conv_shape(h, w, layer):\n",
    "            h = (h - layer.kernel_size[0] + 2 * layer.padding[0]) // layer.stride[0] + 1\n",
    "            w = (w - layer.kernel_size[1] + 2 * layer.padding[1]) // layer.stride[1] + 1\n",
    "            return h // 2, w // 2  # after max-pooling\n",
    "\n",
    "        for conv in [self.conv1, self.conv2, self.conv3, self.conv4]:\n",
    "            h, w = conv_shape(h, w, conv)\n",
    "        \n",
    "        return h, w\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x), 2))\n",
    "        \n",
    "        x = x.view(-1, self.num_flatten)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, self.dropout_rate)\n",
    "        return F.log_softmax(self.fc2(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and Validation Function\n",
    "def train_val(model, params, device):\n",
    "    optimizer = params['optimizer']\n",
    "    loss_func = params['loss_func']\n",
    "    lr_scheduler = params['lr_scheduler']\n",
    "    epochs = params['epochs']\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "        # training phase\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0, 0\n",
    "        \n",
    "        for imgs, labels in params['train_loader']:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "        \n",
    "        # validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in params['val_loader']:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                val_loss += loss_func(outputs, labels).item()\n",
    "                val_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "        \n",
    "        # learning rate scheduler\n",
    "        lr_scheduler.step(val_loss)\n",
    "        \n",
    "        # update best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        # logging\n",
    "        train_acc = train_correct / len(params['train_loader'].dataset)\n",
    "        val_acc = val_correct / len(params['val_loader'].dataset)\n",
    "        history['train_loss'].append(train_loss / len(params['train_loader']))\n",
    "        history['val_loss'].append(val_loss / len(params['val_loader']))\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams and initalization\n",
    "params_model = {\n",
    "    'input_shape': (3, 256, 256),\n",
    "    'init_filters': 8,\n",
    "    'fc_units': 100,\n",
    "    'num_classes': 2,\n",
    "    'dropout_rate': 0.25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cnn_model = CNN_TUMOR(params_model).to(device)\n",
    "\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=3e-4)\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=1)\n",
    "loss_func = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train = {\n",
    "    'train_loader': train_loader,\n",
    "    'val_loader': val_loader,\n",
    "    'optimizer': optimizer,\n",
    "    'lr_scheduler': lr_scheduler,\n",
    "    'loss_func': loss_func,\n",
    "    'epochs': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and validate\n",
    "cnn_model, history = train_val(cnn_model, params_train, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    required_keys = ['train_loss', 'val_loss', 'train_acc', 'val_acc']\n",
    "    if not all(key in history for key in required_keys):\n",
    "        print(\"History dictionary is missing required keys.\")\n",
    "        return\n",
    "\n",
    "    # extract loss and acc from the history dictionary\n",
    "    train_loss = history['train_loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_acc = history['train_acc']\n",
    "    val_acc = history['val_acc']\n",
    "\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # create subplots\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    # plot loss\n",
    "    axs[0].plot(epochs, train_loss, label='Train Loss', color='blue')\n",
    "    axs[0].plot(epochs, val_loss, label='Validation Loss', color='orange')\n",
    "    axs[0].set_title('Loss History')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # plot acc\n",
    "    axs[1].plot(epochs, train_acc, label='Train Accuracy', color='green')\n",
    "    axs[1].plot(epochs, val_acc, label='Validation Accuracy', color='red')\n",
    "    axs[1].set_title('Accuracy History')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "cnn_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = cnn_model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLA_label)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
