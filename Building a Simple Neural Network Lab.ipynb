{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab: Building a Simple Neural Network**\n",
    "\n",
    "In this lab, you will build a basic neural network using Python and the Keras library (a high-level API of TensorFlow). You will learn how to set up layers, compile the model, and train it on a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Setting up the Environment**\n",
    "\n",
    "Before starting, ensure that you have the necessary libraries installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: Loading the Dataset**\n",
    "\n",
    "For this lab, we will use the **MNIST dataset**, which consists of handwritten digits (0–9). Each image is 28x28 pixels, and the task is to classify each image into the correct digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data by scaling pixel values to range [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3: Visualizing the Data** \n",
    "\n",
    "Let’s visualize some of the images from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 images in the dataset\n",
    "for i in range(5):\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.title(f'Label: {y_train[i]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4: Building the Neural Network**\n",
    "\n",
    "Now, let’s build a simple **Fully Connected Neural Network (FCNN)** using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Flatten the input data (28x28 images) into a 1D vector (size 784)\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Add a fully connected (dense) layer with 128 neurons and ReLU activation\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add another fully connected layer with 64 neurons and ReLU activation\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output layer with 10 neurons (one for each digit 0-9), using softmax activation\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 5: Compiling the Model**\n",
    "\n",
    "We need to compile the model, specifying the optimizer, loss function, and evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 6: Training the Model**\n",
    "\n",
    "We will now train the model using the training dataset. The training process will adjust the weights and biases in the network to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 7: Evaluating the Model**\n",
    "\n",
    "After training, we can evaluate the model on the test data to see how well it performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'\\nTest Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 8: Plotting Training Results**\n",
    "\n",
    "To gain insights into how the model performed during training, let’s plot the accuracy and loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 9: Making Predictions**\n",
    "\n",
    "Finally, let’s use the trained model to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the first 5 test images\n",
    "predictions = model.predict(x_test[:5])\n",
    "\n",
    "# Show the images along with the model’s predictions\n",
    "for i in range(5):\n",
    "    plt.imshow(x_test[i], cmap='gray')\n",
    "    plt.title(f'Predicted: {predictions[i].argmax()}, Actual: {y_test[i]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Questions:**\n",
    "\n",
    "1) Why is it necessary to normalize the dataset before training the model?\n",
    "2) What activation function did you use for the hidden layers, and why is it commonly used in neural networks?\n",
    "3) What is the purpose of the softmax activation function in the output layer?\n",
    "4) Why do we use both training and validation data when training the model?\n",
    "5) What factors can affect the accuracy of a neural network?\n",
    "6) Describe one possible improvement you could make to this neural network model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
